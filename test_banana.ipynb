{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import base64\n",
    "import banana_dev as banana\n",
    "\n",
    "api_key = \"b8a9adf0-ec17-4013-a53e-76e4ea7d848c\"\n",
    "model_key = \"d4fd738f-166d-4876-84eb-b0a4b730a88c\"\n",
    "\n",
    "# Expects an mp3 file named test.mp3 in directory\n",
    "with open(f'whisper.mp3', 'rb') as file:\n",
    "    mp3bytes = BytesIO(file.read())\n",
    "mp3 = base64.b64encode(mp3bytes.getvalue()).decode(\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 8.47 ms, total: 113 ms\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_payload = {\"mp3BytesString\": mp3}\n",
    "\n",
    "%time out = banana.run(api_key, model_key, model_payload)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" Hey everyone, welcome to this video. My name is Blake, I'm with Banana and today I'm going to walk you through how you can deploy Open AI's new whisper model on our serverless GPU platform. This is going to be a pretty quick tutorial So let's jump in First thing you're going to want to do is create a banana account or if you already have one simply sign in And then you'll be taken to your banana dashboard, which will look something like this And then from here all we want to do is click new model and then you'll be presented with a choice Instant deploy from a template or deploy from your GitHub repo. So in our case We already have a template for whisper available for everyone that signs up to banana So this is what makes it so fast If you were to deploy a custom model or your own custom version of whisper then you would maybe go this route to connect with your GitHub repo But this is all we need to do. Instant deploy from a template. We'll click that And then we will choose whisper from the drop down and we'll hit deploy And then we just wait a couple seconds here and the model will load up once the model appears We can click into it and you can see the deployment status. So in our case, it's deployed, which is great And then from here what you want to do is we'll jump to the call API tab And you have a code snippet prebuilt for you to copy paste and you can basically take this code snippet now and put it into your program Put it into your product wherever you want to utilize whisper and you're good to go This is a callable template. So that is technically the end of deploying whisper Now if you want to see it actually in action, I will show you with a test file right now So you can continue watching if you want So let's do that now So I'm going to just copy this the nice thing about this code snippet is your API key and the whisper model key specific to your template is auto filled in here so you don't have to worry about grabbing that Let's open up a code editor now So in our case, we're going to be using VS code And you're going to want to basically create a file directory where you'll have two things One is the audio clip that you want to pass into whisper And then the and that's saved as an MP3 and then the other is you're just going to make a test out Pi file which I have here. So let's paste in our code And we are going to save that and then you'll want to open up a terminal with within that same directory that you're working in Next we're going to create a virtual environment. So I'm just going to whip one up here And let's Paste this next command in. Oops. There we go. Okay. And within the virtual environment We need to install banana. So let's go pip install Banana dev underscore dev Excellent and then from here all we really need to do at this point is test it So we're going to just do Python 3 and then the file name. So in this case test.py Now The audio that I used just to verify that this works I'm going to hit run. So I'll just enter. It's going to run the audio that I use is I took the Official trailer 30 seconds of the official trailer of the movie bananas A Woody Allen movie So and now Woody Allen with a few words about his new film. What's the title of your movie Woody? Banana's yes bananas. Uh, the name of the movie is bananas Great clip. So uh, basically that's just going to be a what we're using for audio. So let's jump back And let's see what it translates here Okay, cool And now Woody Allen with a few words about his new film. What's the title of your movie Woody? Banana's yes Ben as so you can see it returns back as a JSON You can see the text is returned right here Excellent. Well, that's a wrap Thanks for watching this tutorial on how to deploy whisper on serverless GPUs I hope you enjoyed it and feel free to leave any questions or comments down below the video and we'll get back to you Otherwise have an awesome time building Cheers\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['modelOutputs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
